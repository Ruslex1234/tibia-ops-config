name: Publish configs to S3 on .configs change

on:
  workflow_dispatch:
  push:
    branches: [ main ]
    paths:
      - '.configs/**'

permissions:
  id-token: write
  contents: read

env:
  AWS_REGION: us-east-1
  S3_BUCKET: ${{ vars.S3_BUCKET || secrets.S3_BUCKET }}
  S3_KEY: configs/combined.json
  DRY_RUN: 'false'
  CONFIG_DIR: .configs
  # Optional SSE:
  # S3_SSE: AES256
  # S3_KMS_KEY_ID: your-kms-id

concurrency:
  group: publish-configs-to-s3
  cancel-in-progress: true

jobs:
  publish:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout (last 2 commits to diff)
        uses: actions/checkout@v4
        with:
          fetch-depth: 2

      - name: Short-circuit if .configs didn't actually change
        id: guard
        shell: bash
        run: |
          set -euo pipefail
          BEFORE="${{ github.event.before }}"
          SHA="${{ github.sha }}"
          # Handle first push / squash merges where BEFORE may be 0000...
          if [[ -z "$BEFORE" || "$BEFORE" == 0000000000000000000000000000000000000000 ]]; then
            echo "first_push=true" >> "$GITHUB_OUTPUT"
            echo "Proceeding (no reliable BEFORE)."
            exit 0
          fi
          CHANGED="$(git diff --name-only "$BEFORE" "$SHA" -- .configs/)"
          if [[ -z "$CHANGED" ]]; then
            echo "No changes under .configs/ in this commit range. Exiting."
            echo "continue=false" >> "$GITHUB_OUTPUT"
            exit 0
          fi
          echo "Changed files under .configs/:"
          echo "$CHANGED"
          echo "continue=true" >> "$GITHUB_OUTPUT"

      - name: Stop early (no .configs changes)
        if: steps.guard.outputs.continue == 'false'
        run: echo "Guard prevented unnecessary work."

      - name: Configure AWS credentials (OIDC)
        if: steps.guard.outputs.continue != 'false' || steps.guard.outputs.first_push == 'true'
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN || vars.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Verify AWS identity
        if: steps.guard.outputs.continue != 'false' || steps.guard.outputs.first_push == 'true'
        run: aws sts get-caller-identity

      - name: Combine .configs/*.json into a single JSON
        if: steps.guard.outputs.continue != 'false' || steps.guard.outputs.first_push == 'true'
        id: combine
        shell: bash
        run: |
          set -euo pipefail
          python - << 'PY'
          import json, os, glob, hashlib
          base = os.environ.get('CONFIG_DIR', '.configs')
          paths = sorted(glob.glob(os.path.join(base, '*.json')))
          if not paths:
            raise SystemExit(f"No JSON files found in {base}")
          combined = {}
          for p in paths:
            name = os.path.basename(p)
            key = name[:-5] if name.endswith('.json') else name
            with open(p, 'r', encoding='utf-8') as f:
              try:
                combined[key] = json.load(f)
              except Exception as e:
                raise SystemExit(f"Failed to parse JSON in {p}: {e}")
          payload = json.dumps(combined, sort_keys=True, separators=(',', ':')).encode('utf-8')
          with open('combined_config.json','wb') as f:
            f.write(payload)
          sha = hashlib.sha256(payload).hexdigest()
          open('combined.sha256','w').write(sha)
          print("Keys:", ",".join(sorted(combined.keys())))
          print("SHA256:", sha)
          print("Bytes:", len(payload))
          PY
          echo "path=combined_config.json" >> "$GITHUB_OUTPUT"

      - name: Upload to S3 (replace existing)
        if: (steps.guard.outputs.continue != 'false' || steps.guard.outputs.first_push == 'true') && env.DRY_RUN != 'true'
        env:
          BUCKET: ${{ env.S3_BUCKET }}
          KEY: ${{ env.S3_KEY }}
        run: |
          set -euo pipefail
          EXTRA_ARGS=()
          if [ -n "${S3_SSE:-}" ]; then EXTRA_ARGS+=(--sse "${S3_SSE}"); fi
          if [ -n "${S3_KMS_KEY_ID:-}" ]; then EXTRA_ARGS+=(--sse-kms-key-id "${S3_KMS_KEY_ID}"); fi
          aws s3 cp "combined_config.json" "s3://${BUCKET}/${KEY}" \
            --only-show-errors \
            --content-type application/json \
            --metadata commit="${GITHUB_SHA}" \
            "${EXTRA_ARGS[@]}"
          echo "Uploaded to s3://${BUCKET}/${KEY}"

      - name: Dry-run notice
        if: env.DRY_RUN == 'true'
        run: echo "DRY_RUN=true; skipping upload."
